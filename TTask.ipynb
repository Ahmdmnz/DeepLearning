{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmdmnz/DeepLearning/blob/main/TTask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqATxfjom1TL"
      },
      "source": [
        "## 1. Encoder Processing\n",
        "### - How the model encodes the question:\n",
        "The input question is: **\"What are the symptoms of diabetes?\"**\n",
        "1. **Tokenization**: The question is first broken into tokens (words/subwords).\n",
        "2. **Embedding**: Each token is converted into a dense vector using learned embeddings.\n",
        "3. **Positional Encoding**: Since Transformers have no recurrence, positional encodings are added to capture word order.\n",
        "4. **Self-Attention Layers**: The embeddings are passed through self-attention and feedforward layers to capture contextual relationships.\n",
        "\n",
        "### - Result of Attention Scores in encoder stage:\n",
        "Attention scores determine how much each word attends to every other word. For example, \"symptoms\" may attend more to \"diabetes\" than to \"what\".\n",
        "\n",
        "### - How Self-Attention Captures Word Relationships:\n",
        "Self-attention calculates interactions between all words, allowing the model to understand dependencies regardless of distance. For instance, it learns that \"symptoms\" relates to \"diabetes\" even though they are not adjacent.\n",
        "\n",
        "### - Significance:\n",
        "Self-attention enables the model to:\n",
        "- Understand the context of each word\n",
        "- Disambiguate meanings based on surrounding words\n",
        "- Improve representation for downstream tasks like question answering\n",
        "\n",
        "---"
      ],
      "id": "XqATxfjom1TL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZG7d7_hm1TL"
      },
      "source": [
        "## 2. Context Processing\n",
        "### - Passage from Medical Paper:\n",
        "> *\"Diabetes is a chronic condition characterized by high blood sugar levels. Common symptoms include increased thirst, frequent urination, extreme fatigue, and blurred vision.\"*\n",
        "\n",
        "### - Encoder-Decoder Attention:\n",
        "In this stage:\n",
        "1. The encoder has already processed the input question.\n",
        "2. The decoder attends to encoder outputs while also accessing the passage.\n",
        "3. Encoder-decoder attention lets the decoder focus on parts of the input relevant to generating the answer.\n",
        "4. In this case, attention would be highest around phrases like *\"increased thirst\"*, *\"frequent urination\"*, etc., since they match the concept of \"symptoms\".\n",
        "\n",
        "---"
      ],
      "id": "cZG7d7_hm1TL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBLWbj-zm1TM"
      },
      "source": [
        "## 3. Decoder Prediction\n",
        "The decoder generates the answer step-by-step using softmax probabilities.\n",
        "\n",
        "### Softmax Probabilities Table:\n",
        "| Step | Candidate Tokens               | Probabilities            |\n",
        "|------|--------------------------------|--------------------------|\n",
        "| 1    | \"Diabetes\" (0.05), \"Increased\" (0.75), \"Common\" (0.2) |\n",
        "| 2    | \"hunger\" (0.1), \"thirst\" (0.8), \"sugar\" (0.1)          |\n",
        "| 3    | \"frequent\" (0.3), \"urination\" (0.6), \"pain\" (0.1)      |\n",
        "| 4    | \"extreme\" (0.2), \"fatigue\" (0.7), \"mild\" (0.1)         |\n",
        "\n",
        "### - Final Prediction:\n",
        "**Step-by-step decoding:**\n",
        "1. Highest prob → **\"Increased\"**\n",
        "2. Highest prob → **\"thirst\"** → \"Increased thirst\"\n",
        "3. Highest prob → **\"urination\"** → likely continuation from \"frequent\"\n",
        "   - But here, \"frequent\" had 0.3 and \"urination\" had 0.6. Since \"frequent urination\" is a common phrase, likely the model learned to implicitly include \"frequent\" → **\"urination\"**\n",
        "4. Highest prob → **\"fatigue\"**\n",
        "\n",
        "###  **Final Answer:**\n",
        "**\"Increased thirst, urination, fatigue\"**\n",
        "\n"
      ],
      "id": "BBLWbj-zm1TM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# this code answers the question"
      ],
      "metadata": {
        "id": "pdggujQ8KzP6"
      },
      "id": "pdggujQ8KzP6"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "model_name = \"t5-base\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "question = \"What are the symptoms of diabetes?\"\n",
        "context = \"Diabetes is a chronic condition characterized by high blood sugar levels. Common symptoms include increased thirst, frequent urination, extreme fatigue, and blurred vision.\"\n",
        "\n",
        "input_text = f\"question: {question} context: {context}\"\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(inputs['input_ids'], max_length=50, num_beams=4, early_stopping=True)\n",
        "\n",
        "generated_answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"Generated Answer: \", generated_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxYp75ZkIASu",
        "outputId": "bbe389e4-b822-46b0-e695-4b6c6c19b427"
      },
      "id": "hxYp75ZkIASu",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Answer:  increased thirst, frequent urination, extreme fatigue, and blurred vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# this code compute self-attention scores in a Transformer encoder for this sentence."
      ],
      "metadata": {
        "id": "4O2z7a_WMQx7"
      },
      "id": "4O2z7a_WMQx7"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "class EnhancedSelfAttention(nn.Module):\n",
        "    def __init__(self, d_model: int = 768, num_heads: int = 8):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "\n",
        "        self.w_q = nn.Linear(d_model, d_model)\n",
        "        self.w_k = nn.Linear(d_model, d_model)\n",
        "        self.w_v = nn.Linear(d_model, d_model)\n",
        "        self.w_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, mask: torch.Tensor = None):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        Q = self.w_q(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        K = self.w_k(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        V = self.w_v(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.d_k)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        attn_weights = F.softmax(scores, dim=-1)\n",
        "        output = torch.matmul(attn_weights, V)\n",
        "\n",
        "        output = output.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
        "        return self.w_o(output), attn_weights\n",
        "\n",
        "def compute_self_attention(sentence: str):\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    inputs = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(**inputs).last_hidden_state\n",
        "\n",
        "    attention_module = EnhancedSelfAttention(d_model=768, num_heads=8)\n",
        "    output, attn_weights = attention_module(embeddings, mask=inputs['attention_mask'])\n",
        "\n",
        "    head0_attn = attn_weights[0, 0].detach().numpy()\n",
        "    print(f\"\\nAttention Scores (Head 1):\")\n",
        "    header = \"\\t\" + \"\\t\".join([f\"{token[:6]}\" for token in tokens])\n",
        "    print(header)\n",
        "    for i, token in enumerate(tokens):\n",
        "        row = \"\\t\".join([f\"{score:.2f}\" for score in head0_attn[i]])\n",
        "        print(f\"{token[:6]}\\t{row}\")\n",
        "\n",
        "    return attn_weights\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    sentence = \"What are the symptoms of diabetes?\"\n",
        "    compute_self_attention(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1VV251bKkv1",
        "outputId": "bfa0d1c4-9cfd-45bd-aff0-cf26db296c16"
      },
      "id": "e1VV251bKkv1",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attention Scores (Head 1):\n",
            "\t[CLS]\twhat\tare\tthe\tsympto\tof\tdiabet\t?\t[SEP]\n",
            "[CLS]\t0.12\t0.10\t0.11\t0.13\t0.11\t0.11\t0.10\t0.10\t0.11\n",
            "what\t0.11\t0.10\t0.12\t0.13\t0.11\t0.12\t0.10\t0.11\t0.10\n",
            "are\t0.13\t0.13\t0.11\t0.12\t0.10\t0.11\t0.10\t0.11\t0.10\n",
            "the\t0.11\t0.11\t0.11\t0.11\t0.11\t0.12\t0.10\t0.11\t0.11\n",
            "sympto\t0.10\t0.10\t0.11\t0.11\t0.11\t0.12\t0.12\t0.11\t0.11\n",
            "of\t0.11\t0.12\t0.11\t0.11\t0.11\t0.11\t0.12\t0.11\t0.11\n",
            "diabet\t0.11\t0.12\t0.11\t0.12\t0.10\t0.12\t0.10\t0.11\t0.11\n",
            "?\t0.13\t0.11\t0.11\t0.11\t0.10\t0.11\t0.10\t0.11\t0.12\n",
            "[SEP]\t0.11\t0.11\t0.11\t0.11\t0.11\t0.12\t0.11\t0.12\t0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ersm--4lMK9h"
      },
      "id": "Ersm--4lMK9h",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}